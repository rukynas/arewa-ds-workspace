{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Day 19\n",
    "\n",
    "#### Exercises: Level 1\n",
    "\n",
    "1. Write a function which count number of lines and number of words in a text. All the files are in the data the folder: \n",
    "   \n",
    "   a) Read obama_speech.txt file and count number of lines and words  \n",
    "   b) Read michelle_obama_speech.txt file and count number of lines and words   \n",
    "   c) Read donald_speech.txt file and count number of lines and words   \n",
    "   d) Read melina_trump_speech.txt file and count number of lines and words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obama_speech.txt not found.\n",
      "michelle_obama_speech.txt not found.\n",
      "donald_speech.txt not found.\n",
      "melania_trump_speech.txt not found.\n"
     ]
    }
   ],
   "source": [
    "def count_lines_and_words(file_path):\n",
    "    # error handling used to minimize error\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            num_lines = len(lines)\n",
    "            words = [word for line in lines for word in line.split()]\n",
    "            num_words = len(words)\n",
    "        return num_lines, num_words\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "speech_files = [\n",
    "    'obama_speech.txt',\n",
    "    'michelle_obama_speech.txt',\n",
    "    'donald_speech.txt',\n",
    "    'melania_trump_speech.txt'\n",
    "]\n",
    "\n",
    "for speech_file in speech_files:\n",
    "    file_path = f'data/{speech_file}'\n",
    "    result = count_lines_and_words(file_path)\n",
    "\n",
    "    if result is not None:\n",
    "        num_lines, num_words = result\n",
    "        print(f\"{speech_file}:\")\n",
    "        print(f\"Number of lines: {num_lines}\")\n",
    "        print(f\"Number of words: {num_words}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{speech_file} not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 2\n",
    "\n",
    "Extract all incoming email addresses as a list from the email_exchange_big.txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'email_exchange_big.txt' not found.\n",
      "Extracted Email Addresses:\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_email_addresses(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Use regular expression to find email addresses\n",
    "        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "        email_addresses = re.findall(email_pattern, content)\n",
    "\n",
    "        return email_addresses\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'email_exchange_big.txt'\n",
    "email_addresses = extract_email_addresses(file_path)\n",
    "\n",
    "print(\"Extracted Email Addresses:\")\n",
    "for address in email_addresses:\n",
    "    print(address)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'sample.txt' not found.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def find_most_common_words(text_or_file, n):\n",
    "    try:\n",
    "        \n",
    "        with open(text_or_file, 'r', encoding='utf-8') as file:\n",
    "                words = re.findall(r'\\b\\w+\\b', file.read())\n",
    "\n",
    "        # Define common English stop words\n",
    "        stop_words = set(['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I'])\n",
    "\n",
    "        # Remove common English stop words\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        # Count occurrences of filtered words\n",
    "        word_counts = Counter(filtered_words)\n",
    "\n",
    "        # Get the top 'n' most common words\n",
    "        top_words = word_counts.most_common(n)\n",
    "\n",
    "        return top_words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{text_or_file}' not found.\")\n",
    "        return []\n",
    "\n",
    "file_path = 'sample.txt'  \n",
    "result_file = find_most_common_words(file_path, 10)\n",
    "print(result_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function, find_most_frequent_words to find: a) The ten most frequent words used in Obama's speech b) The ten most frequent words used in Michelle's speech c) The ten most frequent words used in Trump's speech d) The ten most frequent words used in Melina's speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File 'dataobamaspeechtxt' not found.\n",
      "Error: File 'datamichelleobamaspeechtxt' not found.\n",
      "Error: File 'datatrumpspeechtxt' not found.\n",
      "Error: File 'datamelaniatrumpspeechtxt' not found.\n",
      "Obama's Speech:\n",
      "[]\n",
      "\n",
      "Michelle Obama's Speech:\n",
      "[]\n",
      "\n",
      "Trump's Speech:\n",
      "[]\n",
      "\n",
      "Melania Trump's Speech:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    return cleaned_text\n",
    "\n",
    "obama_speech_path = 'data/obama_speech.txt'\n",
    "michelle_obama_speech_path = 'data/michelle_obama_speech.txt'\n",
    "trump_speech_path = 'data/trump_speech.txt'\n",
    "melania_trump_speech_path = 'data/melania_trump_speech.txt'\n",
    "\n",
    "# Find the ten most frequent words in each speech\n",
    "obama_frequent_words = find_most_common_words(clean_text(obama_speech_path), 10)\n",
    "michelle_obama_frequent_words = find_most_common_words(clean_text(michelle_obama_speech_path), 10)\n",
    "trump_frequent_words = find_most_common_words(clean_text(trump_speech_path), 10)\n",
    "melania_trump_frequent_words = find_most_common_words(clean_text(melania_trump_speech_path), 10)\n",
    "\n",
    "# Print the results\n",
    "print(\"Obama's Speech:\")\n",
    "print(obama_frequent_words)\n",
    "\n",
    "print(\"\\nMichelle Obama's Speech:\")\n",
    "print(michelle_obama_frequent_words)\n",
    "\n",
    "print(\"\\nTrump's Speech:\")\n",
    "print(trump_frequent_words)\n",
    "\n",
    "print(\"\\nMelania Trump's Speech:\")\n",
    "print(melania_trump_frequent_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsatesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
